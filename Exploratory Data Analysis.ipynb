{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis with the Simulacrum\n",
    "Here we explore the data structure of the Simulacrum with a view to writing a synthetic data generator in Python according to the methodology described [here][1].<br/>\n",
    "The `bnlearn` package for R presents a possible alternative implementation. Find out more at http://www.bnlearn.com/, where [lecture][2] [slides][3] on the general theory of Bayesian Networks can also be found.\n",
    "\n",
    "[1]: https://simulacrum.healthdatainsight.org.uk/wp/wp-content/uploads/2018/11/Methodology-Overview-Nov18.pdf\n",
    "[2]: http://www.bnlearn.com/about/teaching/slides-bnshort.pdf\n",
    "[3]: http://www.bnlearn.com/about/slides/slides-useRconf13.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the data from the .csv file\n",
    "Code to extract the data from database using SQL will also be provided soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import os\n",
    "# Please set the path below as per your system data folder location\n",
    "data_path = ['simulacrum_release_v1.1.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "filepath = os.sep.join(data_path + ['sim_av_tumour.csv'])\n",
    "data = pd.read_csv(filepath, sep=',', dtype=str).fillna('NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fun with `ipywidgets` and the `interact` user interface. Read the docs [here](https://ipywidgets.readthedocs.io/en/stable/examples/Using%20Interact.html).<br/>\n",
    "Here we examine the unique values appearing in each column of the table and their frequencies, including missing values which are displayed as `'NaN'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "def view_value_counts(column='BEHAVIOUR_ICD10_O2', data=data):\n",
    "    return data[column].value_counts(dropna=False)\n",
    "\n",
    "interact(view_value_counts, column=list(data.columns));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the table records data up into strata defined by the tumourâ€™s cancer site\n",
    "Select the breast cancer stratum from the tumour table using `SITE_ICD10_O2_3CHAR` == 'C50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.loc[data['SITE_ICD10_O2_3CHAR'] == 'C50', :] # Select the breast cancer stratum from the tumour table\n",
    "\n",
    "# View the first 5 rows in the table after selecting the breast cancer stratum\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing: encode data categories with integer labels\n",
    "We encode the labels in each column as nonnegative integers using scikit-learn's `LabelEncoder` class.<br/>\n",
    "For example, each `SITE_ICD10_O2` cancer site code will be mapped uniquely to a nonnegative integer.<br/>\n",
    "This is necessary in order to compute $\\chi^2$ values using scikit-learn's `chi2` function to assess the correlation between columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Select the columns to compare using the chi-squared statistic\n",
    "# In particular we exclude patient ID, tumour ID, and link number\n",
    "comparison_cols = list(data.columns)[2:]\n",
    "comparison_cols.remove('LINKNUMBER')\n",
    "\n",
    "# Keep track of the label encoders for each column in a dictionary\n",
    "label_encoder_dict = {col_name: LabelEncoder().fit(data[col_name]) for col_name in comparison_cols}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Swap out the string labels for their corresponding integer encodings in place within the dataframe\n",
    "# cleaned = data.copy() can be used if we want to retain a copy of the raw data\n",
    "for col_name, encoder in label_encoder_dict.items():\n",
    "    data[col_name] = encoder.transform(data[col_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can take a look at the categories of data which appear in each column. These should be the same as the categories which appeared in the value counts cell above, but instead of ordering by frequency, here the displayed order corresponds to the way the categories have been encoded as integers.<br/>\n",
    "For example, the first class which appears in the list will be encoded by the number 0, the second class in the list will be encoded as 1, and so on..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_label_encodings(feature='SITE_ICD10_O2'):\n",
    "    r'''Returns the list of classes that were encoded for a given feature column, in order'''\n",
    "    return label_encoder_dict[feature].classes_\n",
    "\n",
    "interact(display_label_encodings, feature=label_encoder_dict.keys());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a dictionary for how missing values 'NaN' have been encoded in each column, if present.<br/>\n",
    "If a column does not have any missing values, then we match the column with the string 'NaN'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NaN_encoding_dict = dict()\n",
    "for key, encoder in label_encoder_dict.items():\n",
    "    try:\n",
    "        NaN_encoding_dict[key] = encoder.transform(['NaN'])[0]\n",
    "    except:\n",
    "        NaN_encoding_dict[key] = 'NaN'\n",
    "#print(pd.Series(NaN_encoding_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the $\\chi^2$ test statistics between pairs of characteristics\n",
    "The mathematical formula for computing $\\chi^2$ test-statistics is described [here](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test#Testing_for_statistical_independence).<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion on handling missing values\n",
    "How do you deal with missing values when computing chi-squared values between pairs of characteristics and why?\n",
    "Do you:\n",
    "1. Treat missing values as a separate category and compute the test statistic between the pair of characteristics over all records (with a given ICD10 site code);\n",
    "2. Treat missing values as a separate category, but ignore records containing missing values for both characteristics (outer join of columns with missing values removed);\n",
    "3. Ignore records containing missing values in either characteristic (inner join of columns with missing values removed);\n",
    "4. Fill missing values, etc.\n",
    "\n",
    "Retaining missing values might inflate test statistics between (relatively) independent characteristics whose missing values are highly correlated (e.g. due to data collection practices), whereas removing records with missing values may distort the results, especially when the remaining data is quite small. Option 2 is a combination of options 1 and 3 and inherits the disadvantages of both.\n",
    "\n",
    "In general, how one deals with missing data requires an understanding of its nature - how was the data collected, what do the missing values represent?\n",
    "- Was the data off the scale of usual measurements (too small or large to register on measuring equipment)?\n",
    "- Were measurements not taken due to faulty or unavailable equipment, or lost due to data corruption or mismanagement?\n",
    "- Etc.\n",
    "\n",
    "When considering the data at hand, we will choose option 1, remaining aware of the caveats mentioned above.\n",
    "\"Some organisations, for instance, have consistently low data quality between some fields and some have high. However missing data in fields (e.g. screening status or tumour staging) is informative (screening was not involved).\"\n",
    "\n",
    "If we choose option 3 we must first select the appropriate rows in the data before computing the test statistic. The code below performs the selection. We can also use SQL to select the relevant data from the database directly, and the corresponding SQL command for this can be found below (soon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_col(column):\n",
    "    r'''Returns a column from a dataframe after dropping encoded missing values'''\n",
    "    return data.loc[~data[column].isin([NaN_encoding_dict[column]]), column]\n",
    "\n",
    "def clean_inner_join(column1='CANCERCAREPLANINTENT', column2='ACE27', verbose=False):\n",
    "    r'''Returns a pair of columns from a dataframe after dropping rows with any encoded missing values'''\n",
    "    clean_col1 = clean_col(column1)\n",
    "    clean_col2 = clean_col(column2)\n",
    "    combined = pd.concat([clean_col1, clean_col2], axis=1, join='inner')\n",
    "    if verbose:\n",
    "        print('Column | preclean size | cleaned size\\n{} | {} | {}\\n{} | {} | {}'.format(\n",
    "            column1, data[column1].size, clean_col1.size, column2, data[column2].size, clean_col2.size))\n",
    "        print('The joined data has shape', combined.shape)\n",
    "    return combined\n",
    "\n",
    "interact(clean_inner_join, column1=comparison_cols, column2=comparison_cols, verbose=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below computes a pair of a $\\chi^2$ test-statistic and the associated p-value for a given pair of columns/characteristics after dropping any records with missing values for the given characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def compute_chi2_value(column1='SITE_ICD10_O2', column2='CREG_CODE'):\n",
    "    combined = clean_inner_join(column1, column2, verbose=True)\n",
    "    return chi2(combined[column1].values.reshape(-1, 1), combined[column2])\n",
    "\n",
    "interact(compute_chi2_value, column1=comparison_cols, column2=comparison_cols);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below computes $\\chi^2$ test statistics between a given characteristic and all the others, taking missing values as a separate category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "def compute_chi2_values(column='SITE_ICD10_O2'):\n",
    "    return chi2(data[comparison_cols], data[column])[0]\n",
    "\n",
    "interact_manual(compute_chi2_values, column=comparison_cols);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine the graph structure\n",
    "For each characteristic, we identify its two highest $\\chi^2$ statistics and selected the corresponding pairs, provided the test-statistic is above a given threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impose a DAG structure on the graph\n",
    "\"We then introduced directions for the edges. Each edge is directed so that it points from a node with\n",
    "a larger number of edges to a node with fewer edges. The result is a directed acyclic graph, i.e. a\n",
    "directional graph where no path starting from a node can lead back that same node.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit our Bayesian Network to the data\n",
    "- Calculate conditional probability distributions based on the data.\n",
    "- Apply hierarchical clustering algorithm to aggregate small groups of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data using the Bayesian Network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rinse, lather, repeat for each cancer site, each data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
