{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Third-party imports\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact\n",
    "import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "# from plotly.subplots import make_subplots\n",
    "import getpass\n",
    "\n",
    "# Local packages\n",
    "from database import connect\n",
    "from populations import pop_queries\n",
    "import queries\n",
    "import analysis\n",
    "import compute_stats\n",
    "import plots\n",
    "from params import key_list, comparison_pairs, filepath_dictionary, field_list_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting to an SQL database with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log into the database\n",
    "username = 'analysisedwardpearce'  # input('username:')\n",
    "db = connect(username, getpass.getpass('password:'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Writing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from write_results import write_counts_to_csv\n",
    "\n",
    "# for count_type in field_list_dict.keys():\n",
    "#     for key in key_list:\n",
    "#         write_counts_to_csv(count_type, key, db)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edward.pearce\\AppData\\Local\\Continuum\\miniconda3\\envs\\idp\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3325: DtypeWarning:\n",
      "\n",
      "Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_types = ['univariate_categorical', 'univariate_dates', 'bivariate_categorical', \n",
    "               'categorical_cross_diagnosis_date', 'categorical_cross_surgery_date', 'surgery_date_cross_diagnosis_date']\n",
    "combined_counts = {count_type: analysis.combine_counts(count_type, analysis.read_counts(count_type)) \n",
    "                   for count_type in count_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_table_sizes = pd.DataFrame({count_type: {pair[0]+' vs. '+pair[1]: frame.shape for pair, frame in comparison_tables.items()} for count_type, comparison_tables in combined_counts.items()}).T\n",
    "joined_table_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from compute_stats import pop_sizes\n",
    "\n",
    "def check_pop_sizes():\n",
    "    for pair, comparison_table in combined_counts['univariate_categorical'].items():\n",
    "        totals_by_category = comparison_table.groupby(by='column_name').sum()\n",
    "        for key in pair:\n",
    "            check = (totals_by_category['counts_'+key] == pop_sizes[key]).all()\n",
    "            print('The number of data entries in the {} cohort is {}: {}'.format(key, pop_sizes[key], check))\n",
    "\n",
    "check_pop_sizes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining the tables of counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Joining directly in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb = pd.read_sql_query(queries.all_counts_query(sim1_pop_query, AV2015_pop_query), db)\n",
    "print(totals_comb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb2 = pd.read_sql_query(queries.all_counts_query(sim2_pop_query, AV2017_pop_query), db)\n",
    "print(totals_comb2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Preliminary checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Some cases of particular interest may include:\n",
    "- Simulated values which are not present in the real dataset (although we typically wouldn't worry about this in the case of datetime fields). Such values could not have been sampled from the real data, and statistical tests cannot be meaningfully carried out on these values since they are not expected to occur at all based on the real data.\n",
    "- Real values which are not present in the simulated dataset. Sometimes this can be explained as reasonable if the values are themselves rare in the real data, however this can also help to identify values which are being significantly underrepresented in the simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb.loc[totals_comb.counts_r == 0].tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split",
    "hidden": true
   },
   "outputs": [],
   "source": [
    "totals_comb.loc[(totals_comb.counts_s == 0) & (totals_comb.counts_r >= 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interact(lambda col_name: plots.view_by_field(totals_comb, col_name), col_name=col_names);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Python's Pandas package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_comparison_tables(count_type, combined_counts):\n",
    "    # Repeat the process of joining tables and filling in the missing zeros\n",
    "    all_joined = pd.merge(combined_counts[count_type][comparison_pairs[0]], combined_counts[count_type][comparison_pairs[1]], \n",
    "                          on=analysis.join_cols[count_type], how='outer')\n",
    "    count_cols = ['counts_'+key for key in key_list]\n",
    "    all_joined[count_cols] = all_joined[count_cols].fillna(0, axis=1).astype('uint32')\n",
    "    return all_joined\n",
    "\n",
    "def check_zeros(table, ignore=['DATE_FIRST_SURGERY', 'DIAGNOSISDATEBEST']):\n",
    "    check = (table == 0).any(axis=1)\n",
    "    for field in ignore:\n",
    "        check = check & (table.column_name != field)\n",
    "    return table.loc[check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interact(lambda col_name: check_zeros(join_comparison_tables('univariate_categorical', combined_counts)).query(\"column_name == '{}'\".format(col_name)), col_name=field_list_dict['univariate_categorical'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting the table of totals (Theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will add the following columns to our table to further analyse and compare the real and simulated datasets:\n",
    "- The fraction/proportion of all entries in the corresponding table which take on a given value\n",
    "- A normal approximation to a binomial test statistic, and a flag for whether the normal approximation is appropriate (further details below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "univariate_z_test_results = {pair: compute_stats.compute_z_test(pair, comparison_table) \n",
    "                             for pair, comparison_table in combined_counts['univariate_categorical'].items()}\n",
    "bivariate_z_test_results = {pair: compute_stats.compute_z_test(pair, comparison_table) \n",
    "                             for pair, comparison_table in combined_counts['bivariate_categorical'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "univariate_chi2_test_results = {pair: compute_stats.compute_chi2_test(pair, comparison_table) \n",
    "                             for pair, comparison_table in combined_counts['univariate_categorical'].items()}\n",
    "bivariate_chi2_test_results = {pair: compute_stats.compute_chi2_test(pair, comparison_table, grouping='bivariate') \n",
    "                             for pair, comparison_table in combined_counts['bivariate_categorical'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_ks_test_results = {pair: compute_stats.compute_ks_test(pair, comparison_table) \n",
    "                             for pair, comparison_table in combined_counts['univariate_dates'].items()}\n",
    "diagnosis_date_ks_test_results = {pair: compute_stats.compute_ks_test(pair, comparison_table, grouping='bivariate')\n",
    "                                  for pair, comparison_table in combined_counts['categorical_cross_diagnosis_date'].items()}\n",
    "surgery_date_ks_test_results = {pair: compute_stats.compute_ks_test(pair, comparison_table, grouping='bivariate')\n",
    "                                  for pair, comparison_table in combined_counts['categorical_cross_surgery_date'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pair, frame in univariate_ks_test_results.items():\n",
    "    print(pair, '\\n', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDFs should be scaled to run from 0 to 1 so that KS-tests are comparable between large and small categories\n",
    "# Area plots could also be used?\n",
    "\n",
    "# Choose date field, comparison pair, and field (column_name1) to view table\n",
    "\n",
    "# for pair, frame in diagnosis_date_ks_test_results.items():\n",
    "#     print(pair, '\\n', frame)\n",
    "\n",
    "# for pair, frame in surgery_date_ks_test_results.items():\n",
    "#     print(pair, '\\n', frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compute_stats.compute_cdf(pair, combined_counts['univariate_dates'][pair]).query(\"column_name == 'DATE_FIRST_SURGERY'\").plot('val', ['cdf_'+key for key in pair],\n",
    "                                                                                                              xlim=('2013', '2016'))\n",
    "# pair = ('sim1', 'av2015')\n",
    "# compute_cdf(pair, combined_counts['univariate_categorical'][pair].query(\"column_name == 'AGE'\")).plot('val', ['cdf_'+key for key in pair])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial test for each category in each field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### One-sample z-test with binomial assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For each category in each column of the simulated `AV_TUMOUR` table (2013-2015 England finalised cohort) we will test the null hypothesis \n",
    "\n",
    "$$H_0: X_{C}\\sim\\mathrm{Bin}(n,\\hat{p}_{C})=\\mathrm{Bin}(1,402,817,E_{C}/1,478,425)$$ \n",
    "\n",
    "that the occurrence $X_{C}$ of category $C$ in the simulated tumour dataset was sampled from a binomial distribution $\\mathrm{Bin}(n,\\hat{p}_{C})$ where $n=1,402,817$ is the number of simulated tumour entries/rows and $\\hat{p}_{C}$ is the proportion of the $1,478,425$ real tumour entries which fall into category $C$, against the alternative hypothesis that the simulated dataset was sampled in some other way (e.g. $X$ binomially distributed with a different value of p; $X$ not binomially distributed (e.g. p not constant between trials or trials not independent, etc), etc.). \n",
    "\n",
    "If n is large enough, then the skew of the Binomial distribution is not too great. In this case a reasonable approximation to $B(n, p)$ is given by the normal distribution $\\mathcal{N}(np,np(1-p))$. - [Wikipedia](https://en.wikipedia.org/wiki/Binomial_distribution#Normal_approximation)\n",
    "\n",
    "In this case we may use the test statistic \n",
    "\n",
    "$$z = \\frac{X - np}{\\sqrt{np(1-p)}}\\sim\\mathcal{N}(0,1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### When is the normal approximation appropriate?\n",
    "\n",
    "The code below draws a graph to illustrate how the continous normal distribution approximates the discrete binomial distribution. The vertical lines show the probability mass functions of different binomial distributions whilst the smooth black lines show the probability distribution functions of their corresponding approximating normal distributions, which are based on the mean and variances of their respective binomial distibution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import binom, norm\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15,10))\n",
    "\n",
    "n = 40\n",
    "colors = ['b', 'y', 'r']\n",
    "probs = [0.7, 0.9, 0.99]\n",
    "binom_dists = [binom(n, p) for p in probs]\n",
    "moments = [drv.stats(moments='mv') for drv in binom_dists]\n",
    "norm_dists = [norm(loc=mv[0], scale=np.sqrt(mv[1])) for mv in moments]\n",
    "\n",
    "x = np.arange(20, 41)\n",
    "#x = [np.arange(drv.ppf(0.005), drv.ppf(0.995)) for drv in binom_dists]\n",
    "x1 = [np.linspace(crv.ppf(0.005), crv.ppf(0.995), 100) for crv in norm_dists]\n",
    "\n",
    "for i in range(len(probs)):\n",
    "    ax.vlines(x, 0, binom_dists[i].pmf(x), color=colors[i], label='p = {} and n = {}'.format(probs[i], n))\n",
    "    ax.plot(x1[i], norm_dists[i].pdf(x1[i]), 'k')\n",
    "ax.set_xlabel('$x$', fontsize = 24) \n",
    "ax.set_ylabel('$P(X=x)$', fontsize = 24) \n",
    "ax.set_title('Binomial distributions and their Normal approximations', fontsize = 24) \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Notice that the as the success probability $p$ gets closer to $0$ or $1$, the binomial distribution gets more skewed/less symmetric, and matches up less well with its normal approximation (which is always symmetric about its mean value). In these extreme cases, the normal approximation also assigns nontrivial probabilities to impossible events under the binomial setup (i.e. more success than trials, or negative number of successes). \n",
    "\n",
    "For these reasons, using the z-test statistic in these cases may lead to misleading results, namely an increased number of Type I errors - rejecting a true null hypothesis, which in our case means identifying more simulated categories as failing to closely match their real counterparts than is truely the case.\n",
    "\n",
    "Therefore we apply the rule which states that the normal approximation is appropriate only if everything within 3 standard deviations of its mean is within the range of possible values; that is, only if\n",
    "\n",
    "$$\\mu \\pm 3\\sigma =np\\pm 3{\\sqrt {np(1-p)}}\\in (0,n)$$\n",
    "\n",
    "This 3-standard-deviation rule is equivalent to the following conditions:\n",
    "\n",
    "$$n>9\\left({\\frac {1-p}{p}}\\right)\\quad {\\text{and}}\\quad n>9\\left({\\frac {p}{1-p}}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We may wish to check the feasibility of calculating the exact binomial test statistics using SciPy in some cases\n",
    "`scipy.stats.binom_test(51, 235, 1.0/6, alternative='two-sided')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Pooled two-sample z-test with binomial assumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "See the explanation [here](https://ncss-wpengine.netdna-ssl.com/wp-content/themes/ncss/pdf/Procedures/PASS/Tests_for_Two_Proportions.pdf)\n",
    "\n",
    "This tests the null hypothesis that \n",
    "\n",
    "Test statistic:\n",
    "\n",
    "$$z = \\frac{\\hat{p}_{1} - \\hat{p}_{2}}{\\sqrt{\\hat{p}(1 - \\hat{p})(\\frac{1}{n_{1}} + \\frac{1}{n_{2}})}}\\sim\\mathcal{N}(0,1)$$\n",
    "\n",
    "where \n",
    "\n",
    "$$\\hat{p} = \\frac{X_{1} + X_{2}}{n_{1} + n_{2}}$$\n",
    "\n",
    "This test has the advantage of still being calculable in the case that $\\hat{p}_{C}=0$ due to zero occurences of a particular value/category in the real data, which might reasonably occur in the case of date fields and some fields relating to rare cancers. The previous one-sample z-test would produce an infinite test statistic when $X\\ne0$ due to dividing by zero, which indicates an expected number of entries in the given category being exactly 0 with absolute certainty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson's chi-squared test and Likelihood-ratio/G-test for each field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can read the Wikipedia pages for background on the various kinds of [multinomial test](https://en.wikipedia.org/wiki/Multinomial_test), namely:\n",
    "- [Pearson's chi-squared test](https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test)\n",
    "![Pearson's chi-squared test](https://wikimedia.org/api/rest_v1/media/math/render/svg/c4fd8945d1bdd2aa3cc133571cb8bb0b232fac3b)\n",
    "- [Likelihood-ratio test](https://en.wikipedia.org/wiki/Likelihood-ratio_test) (a.k.a. [G-test](https://en.wikipedia.org/wiki/G-test))\n",
    "![G-test](https://wikimedia.org/api/rest_v1/media/math/render/svg/fefb45c7ddf75da6452e9bfdcb17925d1b690552)\n",
    "\n",
    "It is necessary to calculate the test statistics based on proportions since the size of the real and simulated datasets are not equal. Number of degrees of freedom equal to number of categories minus 1?\n",
    "\n",
    "We apply a [Wilson–Hilferty transformation](https://en.wikipedia.org/wiki/Chi-squared_distribution#Asymptotic_properties) to the Pearson's chi-squared test statistics which approximately normalizes them (under the null hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test results: Pandas implementation + Plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618a22c781f64ef7a95a24d80c202680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='col_name', options=('QUINTILE_2015', 'CREG_CODE', 'GRADE', 'SEX', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(col_name)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lambda col_name: plots.plot_univariate_categorical_results(univariate_z_test_results, col_name), col_name=field_list_dict['univariate_categorical'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeat for bivariate categorical counts tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74076a16cfa74acb98704300a77c9e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='col_name1', options=('QUINTILE_2015', 'CREG_CODE', 'GRADE', 'SEX',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(col_name1, col_name2)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(lambda col_name1, col_name2: plots.plot_bivariate_categorical_results(bivariate_z_test_results, col_name1, col_name2) \n",
    "         if col_name1 != col_name2 else plots.plot_univariate_categorical_results(univariate_z_test_results, col_name1),\n",
    "         col_name1=field_list_dict['univariate_categorical'], col_name2=field_list_dict['univariate_categorical'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kolmogorov-Smirnov tests for univariate counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Kolmogorov-Smirnov test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test#Two-sample_Kolmogorov%E2%80%93Smirnov_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Diagnosis Date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Date of First Surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_date_results = {date_type: univariate_results.loc[univariate_results.column_name == date_type, \n",
    "                                                             ['val'] + ['counts_'+key for key in key_list] + ['proportion_'+key for key in key_list]] \n",
    "                           for date_type in field_list_dict['univariate_dates']}\n",
    "\n",
    "cumsum_results = pd.concat([univariate_date_results['DIAGNOSISDATEBEST'].val, univariate_date_results['DIAGNOSISDATEBEST'][['counts_'+key for key in key_list] + ['proportion_'+key for key in key_list]].cumsum()], axis=1)\n",
    "cumsum_results['CDF_diff_sim1_av2015'] = (cumsum_results.proportion_sim1 - cumsum_results.proportion_av2015).abs()\n",
    "cumsum_results['CDF_diff_sim2_av2017'] = (cumsum_results.proportion_sim2 - cumsum_results.proportion_av2017).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks_raw = cumsum_results[['CDF_diff_sim1_av2015', 'CDF_diff_sim2_av2017']].max()\n",
    "ks_normalized = dict()\n",
    "ks_normalized['sim1_av2015'] = ks_raw[0] * np.sqrt((pop_sizes['sim1'] * pop_sizes['av2015'])/(pop_sizes['sim1'] + pop_sizes['av2015']))\n",
    "ks_normalized['sim2_av2017'] = ks_raw[1] * np.sqrt((pop_sizes['sim2'] * pop_sizes['av2017'])/(pop_sizes['sim2'] + pop_sizes['av2017']))\n",
    "print(ks_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumsum_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "x_vals = cumsum_results['val_clean']\n",
    "for key in key_list:\n",
    "    y_vals = cumsum_results['proportion_'+key]\n",
    "    fig.add_trace(go.Scatter(x=x_vals, y=y_vals, name=\"CDF: \"+key))\n",
    "\n",
    "fig.update_layout(title_text='Time Series with Rangeslider',\n",
    "                  xaxis_rangeslider_visible=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Test results: SQL implementation + matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Table and plots - Sim1 vs. AV2015 cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "analysis_df = pd.read_sql_query(queries.compute_stats_query(pop_queries['sim1'], pop_queries['av2015']), db)\n",
    "analysis_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interact(lambda col_name: plots.view_by_field(analysis_df, col_name), col_name=col_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interact(lambda col_name, plot_type: plots.plot_by_category(analysis_df, col_name, plot_type), \n",
    "         col_name=col_names, plot_type=plot_params_dict.keys());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Results: Table and plots - Sim2 vs. AV2017 cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analysis_df2 = pd.read_sql_query(queries.compute_stats_query(pop_queries['sim2'], pop_queries['av2017']), db)\n",
    "analysis_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interact(lambda col_name: plots.view_by_field(analysis_df2, col_name), col_name=col_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "interact(lambda col_name, plot_type: plots.plot_by_category(analysis_df2, col_name, plot_type), \n",
    "         col_name=col_names, plot_type=plot_params_dict.keys());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluating the test results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analysis_df.iloc[:,2:].abs().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analysis_df[['binom_z_test_one_sample', 'z_test_two_sample_pooled']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "analysis_df[['binom_z_test_one_sample', 'z_test_two_sample_pooled']].plot.box(vert=False, figsize=(15, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "fig, axes = plt.subplots(2,1, figsize=(15,10))\n",
    "\n",
    "# First plot standard normal distributions on both axes for reference\n",
    "x = np.linspace(norm.ppf(0.0001), norm.ppf(0.9999), 100)\n",
    "for ax in axes:\n",
    "    ax.plot(x, norm.pdf(x), 'k')\n",
    "# Now plot the histograms of test-statistic values\n",
    "analysis_df[['binom_z_test_one_sample']].hist(bins=2500, density=True, ax=axes[0])\n",
    "analysis_df[['z_test_two_sample_pooled']].hist(bins=2500, density=True, ax=axes[1])\n",
    "# Set the limits for the x-axis\n",
    "axes[0].set_xlim(-7,7);\n",
    "axes[0].set_title('Histogram of one-sample z-test statistics over all categories in all fields', fontsize = 24);\n",
    "axes[1].set_xlim(-7,7);\n",
    "axes[1].set_title('Histogram of two-sample z-test statistics over all categories in all fields', fontsize = 24);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "fig, axes = plt.subplots(2,1, figsize=(15,10))\n",
    "\n",
    "# First plot standard normal distributions on both axes for reference\n",
    "x = np.linspace(norm.ppf(0.0001), norm.ppf(0.9999), 100)\n",
    "for ax in axes:\n",
    "    ax.plot(x, norm.pdf(x), 'k')\n",
    "# Now plot the histograms of test-statistic values\n",
    "analysis_df2[['binom_z_test_one_sample']].hist(bins=2500, density=True, ax=axes[0])\n",
    "analysis_df2[['z_test_two_sample_pooled']].hist(bins=2500, density=True, ax=axes[1])\n",
    "# Set the limits for the x-axis\n",
    "axes[0].set_xlim(-7,7);\n",
    "axes[0].set_title('Histogram of one-sample z-test statistics over all categories in all fields', fontsize = 24);\n",
    "axes[1].set_xlim(-7,7);\n",
    "axes[1].set_title('Histogram of two-sample z-test statistics over all categories in all fields', fontsize = 24);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "fig, ax = plt.subplots(1,1, figsize=(15,10))\n",
    "\n",
    "# First plot standard normal distributions on both axes for reference\n",
    "x = np.linspace(norm.ppf(0.0001), norm.ppf(0.9999), 100)\n",
    "ax.plot(x, norm.pdf(x), 'k')\n",
    "# Now plot the histograms of test-statistic values\n",
    "analysis_df[['z_test_two_sample_pooled']].hist(bins=2500, density=True, ax=ax)\n",
    "# Set the limits for the x-axis\n",
    "ax.set_xlim(-7,7)\n",
    "ax.set_title('Histogram of two-sample z-test statistics over all categories in all fields', fontsize = 24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting plots and chi-squared calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables = ['PERFORMANCESTATUS', 'CNS', 'ACE27', 'N_BEST']\n",
    "# for variable in variables:\n",
    "#     plots.plot_by_category(analysis_df, variable, 'Pooled Two-sample Binomial z-test')\n",
    "#     plt.savefig(\"z_test_plot_{}.png\".format(variable), transparent=False, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "analysis_df['f_exp'] = analysis_df.counts_r * (1402817/1462158)\n",
    "chi2_tests = dict()\n",
    "chi2_p_vals = dict()\n",
    "for col_name in col_names:\n",
    "    counts = analysis_df.loc[analysis_df.col_name == col_name]\n",
    "    chi2_tests[col_name] = chisquare(counts['counts_s'], counts['f_exp'])[0]\n",
    "    chi2_p_vals[col_name] = chisquare(counts['counts_s'], counts['f_exp'])[1]\n",
    "results = pd.DataFrame([chi2_tests, chi2_p_vals]).T\n",
    "results#.plot.bar(figsize=(15,10), ylim=(0, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = analysis_df.groupby(by='col_name')\n",
    "results = pd.concat([grouped.size(), grouped['pearson_summand'].sum(), 2 * grouped['lr_summand'].sum(), grouped.size() - 1], axis=1)\n",
    "results.columns = ['num_cats', 'Pearson_chi2_test', 'Likelihood_ratio_test', 'degrees_of_freedom']\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def myfunc(col_name):\n",
    "#     return counts_tables['sim1'].loc[(counts_tables['sim1'].column_name == col_name)].plot.bar('val_clean', 'counts_sim1')\n",
    "# interact(myfunc, col_name=col_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "225.994px",
    "left": "1341.99px",
    "right": "20px",
    "top": "119.989px",
    "width": "362.983px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
